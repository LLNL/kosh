{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting to a Store and Adding Datasets\n",
    "\n",
    "In this Notebook we create a new store and add a few datasets to it.\n",
    "\n",
    "## Connect to store (using sina local file)\n",
    "\n",
    "First let's create an empty databse (with you as a single user)\n",
    "\n",
    "In a real application only admin user should have write permission to the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shlex\n",
    "from subprocess import Popen, PIPE\n",
    "import kosh\n",
    "\n",
    "kosh_example_sql_file = \"kosh_example.sql\"\n",
    "\n",
    "# Create a new store (erase if exists)\n",
    "store = kosh.connect(kosh_example_sql_file, delete_all_contents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  kosh import connect\n",
    "import os\n",
    "\n",
    "# connect to store\n",
    "store = connect(kosh_example_sql_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding datasets to the store\n",
    "\n",
    "Let's add the first 10 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we found: 125 runs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/g19/cdoutrix/miniconda3/envs/kosh/lib/python3.7/site-packages/ipykernel_launcher.py:3: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce37129f9a34fbf800414177459c73a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET NAME: run_000\n",
      "DATASET NAME: run_001\n",
      "DATASET NAME: run_002\n",
      "DATASET NAME: run_003\n",
      "DATASET NAME: run_004\n",
      "DATASET NAME: run_005\n",
      "DATASET NAME: run_006\n",
      "DATASET NAME: run_007\n",
      "DATASET NAME: run_008\n",
      "DATASET NAME: run_009\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "try:\n",
    "    from tqdm.autonotebook import tqdm\n",
    "except:\n",
    "    tqdm = list\n",
    "\n",
    "runs = glob.glob(\"sample_files/run*hdf5\")\n",
    "print(\"we found: {} runs\".format(len(runs)))\n",
    "\n",
    "for run in tqdm(runs[:10]):\n",
    "    name = os.path.basename(run).split(\".\")[0]\n",
    "    print(\"DATASET NAME:\", name)\n",
    "    # let's make sure it is unique, in case we run this cell multiple times\n",
    "    datasets = list(store.find(name=name))\n",
    "    if len(datasets) == 0:\n",
    "        store.create(name)\n",
    "    else:\n",
    "        print(\"we found {} datasets already matching this name\".format(len(datasets)))\n",
    "        print(datasets[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding attributes do a dataset\n",
    "\n",
    "For each of these runs let's add metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1509c1ebc4e74ed7811dd6076d42057c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KOSH DATASET\n",
      "\tid: f4e60cb29dac4dcbbbf51460af73b8a9\n",
      "\tname: run_009\n",
      "\tcreator: cdoutrix\n",
      "\n",
      "--- Attributes ---\n",
      "\tcreator: cdoutrix\n",
      "\tname: run_009\n",
      "\tparam1: 0.46033554077671224\n",
      "\tparam2: 1.3555517113979287\n",
      "\tparam3: 0.16588903647389464\n",
      "\tparam4: 0.07910886294091912\n",
      "\tparam5: 2.258409546589035\n",
      "\tparam6: Z\n",
      "\tproject: Kosh Tutorial\n",
      "--- Associated Data (0)---\n",
      "--- Ensembles (0)---\n",
      "\t[]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def create_metadata():\n",
    "    metadata = {\"param1\": random.random() * 2.,\n",
    "                \"param2\": random.random() * 1.5,\n",
    "                \"param3\": random.random() * 5,\n",
    "                \"param4\": random.random() * 3,\n",
    "                \"param5\": random.random() * 2.5,\n",
    "                \"param6\": chr(random.randint(65, 91)),\n",
    "               }\n",
    "    metadata[\"project\"] = \"Kosh Tutorial\"\n",
    "    return metadata\n",
    "\n",
    "pbar = tqdm(runs[:10])\n",
    "for run in pbar:\n",
    "    name = os.path.basename(run).split(\".\")[0]\n",
    "    # Retrieve dataset via name\n",
    "    dataset = list(store.search(name=name))[0]\n",
    "    # Let's create a few random attributes\n",
    "    metadata = create_metadata()\n",
    "    for attribute in metadata:\n",
    "        setattr(dataset, attribute, metadata[attribute])\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating datasets with all the metadata at once.\n",
    "\n",
    "Writing datasets attributes one at a time, meant accessing the store and editing every single time. This can be slow.\n",
    "\n",
    "Let's speeds things up by writing all the attributes at once.\n",
    "\n",
    "We will also turn to asynchronous mode on to speed up things further. This means we will only write to the store when the user says so. At that time Kosh will double check that nobody else changes any of these attributes while you were in async mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab9e567a61f472eb75f9e78147a19a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KOSH DATASET\n",
      "\tid: 339db962b00e4965950acd3d7eabc03f\n",
      "\tname: run_106\n",
      "\tcreator: cdoutrix\n",
      "\n",
      "--- Attributes ---\n",
      "\tcreator: cdoutrix\n",
      "\tname: run_106\n",
      "\tparam1: 0.1885545362201031\n",
      "\tparam2: 1.3196681267696033\n",
      "\tparam3: 1.9975781451268841\n",
      "\tparam4: 2.0801721610187065\n",
      "\tparam5: 1.3531907909084304\n",
      "\tparam6: V\n",
      "\tproject: Kosh Tutorial\n",
      "--- Associated Data (0)---\n",
      "--- Ensembles (0)---\n",
      "\t[]\n"
     ]
    }
   ],
   "source": [
    "store.synchronous(False)\n",
    "pbar = tqdm(runs[10:])\n",
    "for i, run in enumerate(pbar):\n",
    "    name = os.path.basename(run).split(\".\")[0]\n",
    "    #pbar.set_description(\"run: {:45}\".format(name))\n",
    "    # let's make sure it is unique\n",
    "    #datasets = store.search(name=name)\n",
    "    datasets=[]\n",
    "    if len(datasets) == 0:\n",
    "        metadata = create_metadata()\n",
    "        dataset = store.create(name, metadata=metadata)\n",
    "    else:\n",
    "        print(\"we found {} datasets already matching this name\".format(len(datasets)))\n",
    "        print(datasets[0])\n",
    "print(dataset)\n",
    "# We need to sync the store to ensure it's written to the database\n",
    "store.sync()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding/Modifying/Deleting Dataset attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['creator', 'id', 'name', 'param1', 'param2', 'param3', 'param4', 'param5', 'param6', 'project']\n"
     ]
    }
   ],
   "source": [
    "# List existing attributes\n",
    "print(dataset.listattributes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['creator', 'id', 'name', 'new_attribute', 'param1', 'param2', 'param3', 'param4', 'param5', 'param6', 'project']\n",
      "new\n"
     ]
    }
   ],
   "source": [
    "# Create a new attribute\n",
    "dataset.new_attribute = \"new\"\n",
    "print(dataset.listattributes())\n",
    "print(dataset.new_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changed\n"
     ]
    }
   ],
   "source": [
    "# modify an attribute\n",
    "dataset.new_attribute = \"changed\"\n",
    "print(dataset.new_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['creator', 'id', 'name', 'new_attribute', 'param1', 'param2', 'param3', 'param4', 'param5', 'param6', 'project', 'yet_another_new_attribute']\n",
      "changed_again\n",
      "yana\n"
     ]
    }
   ],
   "source": [
    "# Modify/add many attributes at once (less db access, faster)\n",
    "dataset.update({\"new_attribute\": \"changed_again\", \"yet_another_new_attribute\":\"yana\"})\n",
    "print(dataset.listattributes())\n",
    "print(dataset.new_attribute)\n",
    "print(dataset.yet_another_new_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['creator', 'id', 'name', 'param1', 'param2', 'param3', 'param4', 'param5', 'param6', 'project']\n"
     ]
    }
   ],
   "source": [
    "# Deleting attributes\n",
    "del(dataset.new_attribute)\n",
    "del(dataset.yet_another_new_attribute)\n",
    "print(dataset.listattributes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting datasets from the store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.delete(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the store\n",
    "\n",
    "When querying the store use a dictionary to specify key/values we want to look for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "datasets = list(store.find(param6='B', ids_only=True))  # Only their ids (faster)\n",
    "print(len(datasets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using sina's query capabilities we can use `ranges` [(more on sina utils here)](https://lc.llnl.gov/workflow/docs/sina/generated_docs/sina.utils.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "from sina.utils import DataRange\n",
    "datasets = list(store.find(param1=DataRange(min=1.7)))\n",
    "print(len(datasets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also search for datasets having a specific attribute (independently of its type or value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n"
     ]
    }
   ],
   "source": [
    "datasets = list(store.find('param1'))\n",
    "# or using sina's tools\n",
    "from sina.utils import exists\n",
    "datasets = list(store.find(param1=exists()))\n",
    "print(len(datasets))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kosh",
   "language": "python",
   "name": "kosh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
