{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kosh Tansformers using SciKit-Learn\n",
    "\n",
    "This notebook introduces some of `sklearn`-based Kosh's *transformers*. \n",
    "\n",
    "\n",
    "## Splitter\n",
    "\n",
    "This transformer allows to split some extracted data between training, test and validation splits\n",
    "\n",
    "It also retuns `n_splits` (default 1) variations\n",
    "\n",
    "It can use any scikit-learn model_selection splitter class (see: [here](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection) for more details)\n",
    "\n",
    "The base class is passed via the `splitter` keyword and defaults to [ShuffleSplitter](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit)\n",
    "\n",
    "A good example of what these splitters do can be found [here](https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py)\n",
    "\n",
    "Deafult values are:\n",
    "`splitter`:`ShuffleSplitter`\n",
    "`n_splits`: `1`\n",
    "`random_state`: `None` (pass an int for reproducibility)\n",
    "`train_size`: `0.9`\n",
    "`test_size`: `0.1`\n",
    "`validation_size`: `0.`\n",
    "\n",
    "A basic example with fake data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default return\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "import kosh\n",
    "import numpy\n",
    "\n",
    "class FakeLoader(kosh.loaders.KoshLoader):\n",
    "    types = {\"fake\":[\"numpy\",]}\n",
    "    def extract(self):\n",
    "        return numpy.arange(1000, dtype=numpy.float32)\n",
    "    def list_features(self):\n",
    "        return \"range_1000\"\n",
    "    \n",
    "store = kosh.connect(\"skl.sql\", delete_all_contents=True)\n",
    "store.add_loader(FakeLoader)\n",
    "\n",
    "dataset = store.create()\n",
    "dataset.associate(\"fake_file.fake\", mime_type=\"fake\")\n",
    "\n",
    "print(\"Default return\")\n",
    "print(len(dataset[\"range_1000\"]()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 100\n"
     ]
    }
   ],
   "source": [
    "splits = dataset.get_execution_graph(\"range_100\", transformers=[kosh.transformers.Splitter(random_state=73)])\n",
    "\n",
    "# Length of split is 1 because we asked for one variation (n_splits=1)\n",
    "train, test = splits()[0]  # No validation by default\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750 150 100\n"
     ]
    }
   ],
   "source": [
    "splits = dataset.get(\"range_100\", transformers=[kosh.transformers.Splitter(random_state=73, test_size=.15, train_size=.75)])\n",
    "train, test, validation = splits[0]  # Now we have validation (train+test < 1.)\n",
    "print(len(train), len(test), len(validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalers\n",
    "\n",
    "These allow to process scikit scalers on a datasets (numpy array)\n",
    "\n",
    "* SKL: can return a SKL estimator (skl_class.fit(input) or the input fitted to each label from the class, all argument to init the class are passed back to skl_class\n",
    "\n",
    "```python\n",
    "class SKL(KoshTransformer):\n",
    "    types = {\"numpy\": [\"estimator\", \"numpy\"]}\n",
    "\n",
    "    def __init__(self, *args, **kargs):\n",
    "        kw = {}\n",
    "        for arg in [\"n_samples\", \"sampling_method\"]:\n",
    "            setattr(self, arg, kargs.pop(arg, None))\n",
    "            kw[arg] = getattr(self, arg)\n",
    "        skl_class = kargs.pop(\"skl_class\")\n",
    "        self.skl_class = skl_class(*args, **kargs)\n",
    "        kw.update(kargs)\n",
    "        super(SKL, self).__init__(*args, **kargs)\n",
    "```\n",
    "\n",
    "For convenience sckit_learn's DBSCAN and KMeans are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([-1, 0, 1], [array([[25, 80]]), array([[1, 2],\n",
      "       [2, 2],\n",
      "       [2, 3]]), array([[8, 7],\n",
      "       [8, 8]])])\n",
      "([-1, 0, 1], [array([[25, 80]]), array([[1, 2],\n",
      "       [2, 2],\n",
      "       [2, 3]]), array([[8, 7],\n",
      "       [8, 8]])])\n"
     ]
    }
   ],
   "source": [
    "from kosh.transformers import DBSCAN\n",
    "import numpy\n",
    "\n",
    "class FakeLoader(kosh.loaders.KoshLoader):\n",
    "    types = {\"fake\":[\"numpy\",]}\n",
    "    def extract(self):\n",
    "        return numpy.array([[1, 2], [2, 2], [2, 3],\n",
    "               [8, 7], [8, 8], [25, 80]])\n",
    "    def list_features(self):\n",
    "        return \"data\"\n",
    "    \n",
    "store = kosh.utils.create_new_db(\"skl.sql\")\n",
    "store.add_loader(FakeLoader)\n",
    "\n",
    "dataset = store.create()\n",
    "dataset.associate(\"fake_file.fake\", mime_type=\"fake\")\n",
    "\n",
    "\n",
    "clustering_transformer = DBSCAN(eps=3, min_samples=2)\n",
    "\n",
    "# Let's get the clustered data back (format='numpy')\n",
    "clustered = dataset.get(\"data\", transformers=[clustering_transformer,])\n",
    "print(clustered)\n",
    "\n",
    "#Let's get back the estimator\n",
    "estimator = dataset.get(\"data\", transformers=[clustering_transformer,], format=\"estimator\")\n",
    "print(estimator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kosh",
   "language": "python",
   "name": "kosh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
