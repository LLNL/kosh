{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kosh Operators\n",
    "\n",
    "This notebook introduces Kosh's *operators*. Unlike *transformers*, which act on a feature itself, *operators* allow post-processing of data coming from different features, for example adding two features together. Either from the same source or not.\n",
    "\n",
    "Kosh operators will receive the input features as Python's `*args`.\n",
    "\n",
    "Operators inputs can be features coming straight from the loader, possibly processed by a(many) *transformer(s)* and/or coming from another *operator*.\n",
    "\n",
    "While one could be be getting each feature individually and then use a raw function on them, operators offer many advantages.\n",
    "\n",
    "* When mixing data from multiple sources, and possibly transformers, Kosh will automatically determine which loaders to use and which output format is required from each loader (and transformers) in order for all data to be compatible when passed to the operator.\n",
    "* Operators can be built (`__getitem__` function see [this notebook](Example_Advanced_Data_Slicing.ipynb) ) to read in only the amount of data needed.\n",
    "\n",
    "\n",
    "## Easiest way: Decorators\n",
    "\n",
    "As with `transformers` one can use Python `decorators` to quickly convert an existing function.\n",
    "\n",
    "Let's import some modules, create a store and a dataset to play with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[74.60042   22.704462  81.75976   43.019024  90.3619    27.78305\n",
      "  71.98507   38.78283   31.862976  12.7631855 94.52985   74.529434\n",
      "  18.101988  57.22014   50.838238  75.56943   21.334723  63.617054 ]\n",
      " [30.224789  70.80611   62.686962  19.330027  81.621056  93.60426\n",
      "  21.645191  63.31401   92.55467   90.84677   27.292467  14.005975\n",
      "  49.63301   85.57087    9.917352  58.027737  69.95087    5.07952  ]]\n",
      "[[24.176632  28.35887   57.926807  88.42995   43.800083  59.017242\n",
      "  22.848253   7.5056286  2.5399094  6.2492366 46.997864  60.64453\n",
      "  30.870817  66.92705   46.292072  27.467634  84.07651   68.11991  ]\n",
      " [73.90602   55.195995  84.13312   79.93733   13.419014  60.481445\n",
      "  64.483665   9.53269   56.463535  92.742775  88.28038   16.180855\n",
      "   4.254545   9.790927  67.85503    1.1167012 63.09269   49.717033 ]]\n"
     ]
    }
   ],
   "source": [
    "import kosh\n",
    "import numpy as np\n",
    "\n",
    "import sys, os\n",
    "store = kosh.connect(\"operators_demo.sql\", delete_all_contents=True)\n",
    "ds = store.create()\n",
    "ds.associate(\"../tests/baselines/node_extracts2/node_extracts2.hdf5\", mime_type=\"hdf5\")\n",
    "\n",
    "m1 = ds[\"node/metrics_0\"]\n",
    "print(m1[:][:])\n",
    "m2 = ds[\"node/metrics_2\"]\n",
    "print(m2[:][:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assuming you have a function that adds up your features for numpy arrays. Let's make it a Kosh operator.\n",
    "\n",
    "*Note:* `numpy_operators` will declare the operator's `types` to be `{'numpy': [\"numpy\",]}`. See later for declaring your custom `types`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 98.777054  51.06333  139.68657  131.44897  134.16199   86.80029\n",
      "   94.83332   46.28846   34.402885  19.012423 141.52771  135.17397\n",
      "   48.972805 124.14719   97.13031  103.03706  105.41123  131.73697 ]\n",
      " [104.13081  126.002106 146.82008   99.26736   95.04007  154.08571\n",
      "   86.12886   72.8467   149.0182   183.58954  115.572845  30.186829\n",
      "   53.887558  95.36179   77.77238   59.14444  133.04355   54.796555]]\n"
     ]
    }
   ],
   "source": [
    "@kosh.numpy_operator\n",
    "def Add(*inputs):\n",
    "    out = inputs[0][:]\n",
    "    for input_ in inputs[1:]:\n",
    "        out += input_[:]\n",
    "    return out\n",
    "\n",
    "add = Add(m1, m2)\n",
    "print(add[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to *loaders* and *transformers*, *operators* must declare the mime_types they can accept as inputs and the mime_types they export these inputs to. Where the *transformers* process the feature via their `transform` function, *operators* must define their `operate` function.\n",
    "\n",
    "At the moment it is expected that all inputs must be from the same mime_type.\n",
    "\n",
    "Let's create an operator while defninig these *mime_types*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 98.777054  51.06333  139.68657  131.44897  134.16199   86.80029\n",
      "   94.83332   46.28846   34.402885  19.012423 141.52771  135.17397\n",
      "   48.972805 124.14719   97.13031  103.03706  105.41123  131.73697 ]\n",
      " [104.13081  126.002106 146.82008   99.26736   95.04007  154.08571\n",
      "   86.12886   72.8467   149.0182   183.58954  115.572845  30.186829\n",
      "   53.887558  95.36179   77.77238   59.14444  133.04355   54.796555]]\n"
     ]
    }
   ],
   "source": [
    "@kosh.typed_operator({\"numpy\":[\"numpy\",]})\n",
    "def Add(*inputs):\n",
    "    out = inputs[0][:]\n",
    "    for input_ in inputs[1:]:\n",
    "        out += input_[:]\n",
    "    return out\n",
    "\n",
    "add = Add(m1, m2)\n",
    "print(add[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again just like loaders and transformers, operator can return the output in multiple format, in this case the decorated function must accept the \"format\" key argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 98.777054  51.06333  139.68657  131.44897  134.16199   86.80029\n",
      "   94.83332   46.28846   34.402885  19.012423 141.52771  135.17397\n",
      "   48.972805 124.14719   97.13031  103.03706  105.41123  131.73697 ]\n",
      " [104.13081  126.002106 146.82008   99.26736   95.04007  154.08571\n",
      "   86.12886   72.8467   149.0182   183.58954  115.572845  30.186829\n",
      "   53.887558  95.36179   77.77238   59.14444  133.04355   54.796555]] <class 'numpy.ndarray'>\n",
      "[[ 98.777054  51.06333  139.68657  131.44897  134.16199   86.80029\n",
      "   94.83332   46.28846   34.402885  19.012423 141.52771  135.17397\n",
      "   48.972805 124.14719   97.13031  103.03706  105.41123  131.73697 ]\n",
      " [104.13081  126.002106 146.82008   99.26736   95.04007  154.08571\n",
      "   86.12886   72.8467   149.0182   183.58954  115.572845  30.186829\n",
      "   53.887558  95.36179   77.77238   59.14444  133.04355   54.796555]] <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "@kosh.typed_operator_with_kwargs({\"numpy\":[\"numpy\",\"str\"]})\n",
    "def Add(*inputs, **kwargs):\n",
    "    out = inputs[0][:]\n",
    "    for input_ in inputs[1:]:\n",
    "        out += input_[:]\n",
    "    if kwargs[\"format\"] == \"numpy\":\n",
    "        return out\n",
    "    elif kwargs[\"format\"] == \"str\":\n",
    "        return str(out)\n",
    "\n",
    "add = Add(m1, m2)\n",
    "print(add(format=\"numpy\"), type(add(format=\"numpy\")))\n",
    "print(add(format=\"str\"), type(add(format=\"str\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A warning about indices\n",
    "\n",
    "Kosh decorators will provide an operator that will pass through the indices a user asked for (for efficiency).\n",
    "See [this notebook](Example_Advanced_Data_Slicing.ipynb) for cases where this will return the wrong answer (e.g a operator that flips the order of the input).\n",
    "\n",
    "## Operator from scratch\n",
    "\n",
    "In this example we will define a simple **Add** operator that will add all the inputs it receives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Add(kosh.KoshOperator):\n",
    "    types = {\"numpy\" : [\"numpy\",]}  # Our operator accepts numpy arrays and outputs numpy arrays\n",
    "    \n",
    "    def operate(self, *inputs, ** kargs):\n",
    "        # *inputs are the input received from their predecessors in the execution graph\n",
    "        # It is important to define **kargs as the function will receive `format=some_format`\n",
    "        out = np.array(inputs[0])\n",
    "        for input_ in inputs[1:]:\n",
    "            out += np.array(input_)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important points**:\n",
    "\n",
    "  * The `operate` function will receive the desired output format via `format=output_format` so it *must* declare `**kargs`\n",
    "  * inputs are sent via `*inputs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22 16]\n"
     ]
    }
   ],
   "source": [
    "f1 = ds[\"cycles\"]\n",
    "add = Add(f1, f1)\n",
    "\n",
    "print(add[:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously mentioned we can also pass the feature through a transformer first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33. 24.]\n"
     ]
    }
   ],
   "source": [
    "class Twice(kosh.transformers.KoshTransformer):\n",
    "    types = {\"numpy\":[\"numpy\",]}\n",
    "    def transform(self, input, format):\n",
    "        return np.array(input) * 2.\n",
    "    \n",
    "twice = Twice()\n",
    "\n",
    "f1 = ds.get_execution_graph(\"cycles\", transformers=[twice,])\n",
    "f2 = ds[\"cycles\"]\n",
    "\n",
    "add2 = Add(f1, f2)\n",
    "print(add2[:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also have an operator as an input to another, and mix and match this with regular features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55. 40.]\n"
     ]
    }
   ],
   "source": [
    "add3 = Add(add2, add)\n",
    "print(add3[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes these can get complicated and hard to follow.\n",
    "You can draw the execution graph to see if everything is happening as you would expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kosh.utils.draw_execution_graph(add3.execution_graph(), png_name=\"exec_graph.png\", output_format=\"numpy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Execution Graph](exec_graph.png)\n",
    "\n",
    "Lastly it is worth noting that transformers and operators can implement their own `__getitem__` function to subset the data. See [this notebook](Example_Advanced_Data_Slicing.ipynb) for more in this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helping the Operators\n",
    "\n",
    "### describing the entries\n",
    "\n",
    "Operators can get inputs from many sources. Sometimes it can be helpful to get an idea of what is likely coming in.\n",
    "\n",
    "the `describe_entries` function returns a generator of `describe_feature` for each entry feature. It will crawl the graph backward when it encounters transformers or operators. If a loader did not implement `describe_feature` an empty dictionary will be used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'size': (2,),\n",
       "  'format': 'hdf5',\n",
       "  'type': dtype('int64'),\n",
       "  'dimensions': [{'name': ''}]},\n",
       " {'size': (2,),\n",
       "  'format': 'hdf5',\n",
       "  'type': dtype('int64'),\n",
       "  'dimensions': [{'name': ''}]},\n",
       " {'size': (2,),\n",
       "  'format': 'hdf5',\n",
       "  'type': dtype('int64'),\n",
       "  'dimensions': [{'name': ''}]},\n",
       " {'size': (2,),\n",
       "  'format': 'hdf5',\n",
       "  'type': dtype('int64'),\n",
       "  'dimensions': [{'name': ''}]},\n",
       " {'size': (2,),\n",
       "  'format': 'hdf5',\n",
       "  'type': dtype('int64'),\n",
       "  'dimensions': [{'name': ''}]},\n",
       " {'size': (2,),\n",
       "  'format': 'hdf5',\n",
       "  'type': dtype('int64'),\n",
       "  'dimensions': [{'name': ''}]},\n",
       " {'size': (2,),\n",
       "  'format': 'hdf5',\n",
       "  'type': dtype('int64'),\n",
       "  'dimensions': [{'name': ''}]},\n",
       " {'size': (2,),\n",
       "  'format': 'hdf5',\n",
       "  'type': dtype('int64'),\n",
       "  'dimensions': [{'name': ''}]},\n",
       " {'size': (2,),\n",
       "  'format': 'hdf5',\n",
       "  'type': dtype('int64'),\n",
       "  'dimensions': [{'name': ''}]},\n",
       " {'size': (2,),\n",
       "  'format': 'hdf5',\n",
       "  'type': dtype('int64'),\n",
       "  'dimensions': [{'name': ''}]}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@kosh.operators.numpy_operator\n",
    "def my_operator(*data, **kargs):\n",
    "    return numpy.concatenate(*data)\n",
    "\n",
    "\n",
    "@kosh.transformers.numpy_transformer\n",
    "def my_transformer(data):\n",
    "    return data\n",
    "\n",
    "store = kosh.connect(\"demo_entries.sql\", delete_all_contents=True)\n",
    "ds = store.create()\n",
    "ds.associate(\"sample_files/run_000.hdf5\",\"hdf5\")\n",
    "c = ds.get_execution_graph(\"cycles\", transformers=my_transformer)\n",
    "double = my_operator(c, c)\n",
    "triple = my_operator(c, c, c)\n",
    "combine = my_operator(double, triple)\n",
    "mixed = my_operator(combine, combine)\n",
    "list(mixed.describe_entries())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requesting Input Datasets\n",
    "\n",
    "Similarly to their `describe_entries()` and the loaders' `get_requestor()` operators have a `get_input_datasets()` function that will return the datasets contributing to the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[KOSH DATASET\n",
       "\tid: a1b64a12f25441e487abf86571feb2c0\n",
       "\tname: Unnamed Dataset\n",
       "\tcreator: cdoutrix\n",
       "\n",
       "--- Attributes ---\n",
       "\tcreator: cdoutrix\n",
       "\tname: Unnamed Dataset\n",
       "--- Associated Data (1)---\n",
       "\tMime_type: hdf5\n",
       "\t\t/g/g19/cdoutrix/git/kosh/examples/sample_files/run_000.hdf5 ( 29e8e99cca9a42319a6552376f8ab1bc )\n",
       "--- Ensembles (0)---\n",
       "\t[]\n",
       "--- Ensemble Attributes ---\n",
       ",\n",
       " KOSH DATASET\n",
       "\tid: a1b64a12f25441e487abf86571feb2c0\n",
       "\tname: Unnamed Dataset\n",
       "\tcreator: cdoutrix\n",
       "\n",
       "--- Attributes ---\n",
       "\tcreator: cdoutrix\n",
       "\tname: Unnamed Dataset\n",
       "--- Associated Data (1)---\n",
       "\tMime_type: hdf5\n",
       "\t\t/g/g19/cdoutrix/git/kosh/examples/sample_files/run_000.hdf5 ( 29e8e99cca9a42319a6552376f8ab1bc )\n",
       "--- Ensembles (0)---\n",
       "\t[]\n",
       "--- Ensemble Attributes ---\n",
       ",\n",
       " KOSH DATASET\n",
       "\tid: a1b64a12f25441e487abf86571feb2c0\n",
       "\tname: Unnamed Dataset\n",
       "\tcreator: cdoutrix\n",
       "\n",
       "--- Attributes ---\n",
       "\tcreator: cdoutrix\n",
       "\tname: Unnamed Dataset\n",
       "--- Associated Data (1)---\n",
       "\tMime_type: hdf5\n",
       "\t\t/g/g19/cdoutrix/git/kosh/examples/sample_files/run_000.hdf5 ( 29e8e99cca9a42319a6552376f8ab1bc )\n",
       "--- Ensembles (0)---\n",
       "\t[]\n",
       "--- Ensemble Attributes ---\n",
       "]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = ds[\"node/metrics_1\"]\n",
    "m2 = ds[\"node/metrics_2\"]\n",
    "m3 = ds[\"node/metrics_3\"]\n",
    "\n",
    "m1_2 = Add(m1, m2)\n",
    "m_f = Add(m3, m1_2)\n",
    "[x for x in m_f.get_input_datasets()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which in this case is not necessarily useful since all data come from the same dataset.\n",
    "\n",
    "### Requesting input loaders\n",
    "\n",
    "In the example above it might be more useful to access the loaders themselves (so we get the feature name and mime_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('/g/g19/cdoutrix/git/kosh/examples/sample_files/run_000.hdf5',\n",
       "  'node/metrics_3',\n",
       "  'hdf5'),\n",
       " ('/g/g19/cdoutrix/git/kosh/examples/sample_files/run_000.hdf5',\n",
       "  'node/metrics_1',\n",
       "  'hdf5'),\n",
       " ('/g/g19/cdoutrix/git/kosh/examples/sample_files/run_000.hdf5',\n",
       "  'node/metrics_2',\n",
       "  'hdf5')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x.uri, x.feature, x._mime_type) for x in m_f.get_input_loaders()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course these can be used by the operators themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADD INPUT DS: ['a1b64a12f25441e487abf86571feb2c0', 'a1b64a12f25441e487abf86571feb2c0']\n",
      "INPUT FEATURES: ['node/metrics_1', 'node/metrics_2']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Add(kosh.KoshOperator):\n",
    "    types = {\"numpy\" : [\"numpy\",]}  # Our operator accepts numpy arrays and outputs numpy arrays\n",
    "    \n",
    "    def operate(self, *inputs, ** kargs):\n",
    "        # *inputs are the input received from their predecessors in the execution graph\n",
    "        # It is important to define **kargs as the function will receive `format=some_format`\n",
    "        datasets = list(self.get_input_datasets())\n",
    "        print(\"ADD INPUT DS:\", [x.id for x in datasets])\n",
    "        loaders = self.get_input_loaders()\n",
    "        print(\"INPUT FEATURES:\", [x.feature for x in loaders])\n",
    "        out = np.array(inputs[0])\n",
    "        for input_ in inputs[1:]:\n",
    "            out += np.array(input_)\n",
    "        return out\n",
    "mf = Add(ds[\"node/metrics_1\"], ds[\"node/metrics_2\"])[:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kosh Environment",
   "language": "python",
   "name": "kosh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
